{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuk1jckZceB8"
      },
      "source": [
        "**import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CeZ8A07-zIxo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import utils\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BDhTxWLY3Fnf"
      },
      "outputs": [],
      "source": [
        "import librosa as lr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**upload dataset**"
      ],
      "metadata": {
        "id": "w3klPzIvuWto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1--C4P9SSZhYnTITWyYpEzNXZwpOKM6tW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpCKYEPJuV2v",
        "outputId": "1e70c190-ebea-4124-93d7-432ca4c4a71c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--C4P9SSZhYnTITWyYpEzNXZwpOKM6tW\n",
            "To: /content/dataset.zip\n",
            "100% 35.0M/35.0M [00:00<00:00, 261MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFpY43U7ud7h",
        "outputId": "29ea5e0f-9719-4824-9297-435570604380"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            "replace dataset/1/1-(1).mp3? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNswjxbTGOMx"
      },
      "outputs": [],
      "source": [
        "labels = ['اوراق', 'ارز', 'سکه', 'بانک', 'طلا', 'نفت', 'مشتقات', 'فلزات', 'صندوق سهامی', 'صندوق درآمد ثابت', 'صندوق مختلط', 'صندوق قابل معامله']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqC5EiRoGqAb",
        "outputId": "80981ef7-80fc-40b8-c67f-b98987a26cde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing data**"
      ],
      "metadata": {
        "id": "CytbPRmWp4im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read dataset**"
      ],
      "metadata": {
        "id": "e-3Y671G23g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**read data.json**"
      ],
      "metadata": {
        "id": "lZNOwa9Hnu7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-322-3NQ84fc2aM2Xg1_LsMf6H8STsZ5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT9DBAIcnoQ7",
        "outputId": "0fb042d8-df2f-4379-da71-8ff6af88910d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-322-3NQ84fc2aM2Xg1_LsMf6H8STsZ5\n",
            "To: /content/data.json\n",
            "100% 270M/270M [00:02<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path):\n",
        "    with open(data_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "GCAOmldr1zHZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data('data.json')"
      ],
      "metadata": {
        "id": "e6d7ZJSO3I2b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyu0VB59wivh",
        "outputId": "e9bdc464-9903-45e8-a822-ed0ffdcb58c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2880, 20, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0:40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_vYLquJ3RUl",
        "outputId": "0d191dc4-5c3d-4c81-a59b-09c625e50dd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق',\n",
              "       'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق',\n",
              "       'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق',\n",
              "       'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق',\n",
              "       'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق',\n",
              "       'اوراق', 'اوراق', 'اوراق', 'اوراق', 'اوراق'], dtype='<U17')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'signal': X.tolist(), 'category': y.tolist()})"
      ],
      "metadata": {
        "id": "Uvz5ld8qUeD-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xcFEBk9rU_sk",
        "outputId": "99e34627-0df1-4abc-a63c-87037fd07798"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              signal category\n",
              "0  [[-591.5642700195312, -591.5642700195312, -591...    اوراق\n",
              "1  [[-267.8851324246888, -265.87160453519965, -26...    اوراق\n",
              "2  [[-536.2584228515625, -531.6232299804688, -529...    اوراق\n",
              "3  [[-601.7645263671875, -601.7645263671875, -601...    اوراق\n",
              "4  [[-616.0204467773438, -616.0204467773438, -616...    اوراق"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cc0278e-39b2-44dc-90ab-d88ed08f5ac4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>signal</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-591.5642700195312, -591.5642700195312, -591...</td>\n",
              "      <td>اوراق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-267.8851324246888, -265.87160453519965, -26...</td>\n",
              "      <td>اوراق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-536.2584228515625, -531.6232299804688, -529...</td>\n",
              "      <td>اوراق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-601.7645263671875, -601.7645263671875, -601...</td>\n",
              "      <td>اوراق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-616.0204467773438, -616.0204467773438, -616...</td>\n",
              "      <td>اوراق</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cc0278e-39b2-44dc-90ab-d88ed08f5ac4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cc0278e-39b2-44dc-90ab-d88ed08f5ac4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cc0278e-39b2-44dc-90ab-d88ed08f5ac4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = pd.get_dummies(y).columns.values"
      ],
      "metadata": {
        "id": "P8qf4WhJwtMi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKhHXX6Nwyvg",
        "outputId": "0cebf68c-e621-4da5-8879-5b6e75ff8d1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ارز', 'اوراق', 'بانک', 'سکه', 'صندوق درآمد ثابت', 'صندوق سهامی',\n",
              "       'صندوق قابل معامله', 'صندوق مختلط', 'طلا', 'فلزات', 'مشتقات',\n",
              "       'نفت'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = pd.get_dummies(y).values"
      ],
      "metadata": {
        "id": "PYIkCDjL_90q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs8J2RP7AHaz",
        "outputId": "91cb4cba-85a2-4831-c8ee-62e78f3cc452"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FhFBE1RDHy6",
        "outputId": "b7651f39-1a93-4e0e-af43-91209364125a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2880"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test(X, y_one_hot):\n",
        "  X_train = []\n",
        "  X_test = []\n",
        "  Y_train = []\n",
        "  Y_test = []\n",
        "  counter = 0\n",
        "  for i in range(len(X)):\n",
        "    if (i+1) % 40 == 0:\n",
        "      x_train, x_test, y_train, y_test = train_test_split(X[counter*40:(counter*40)+40], y_one_hot[counter*40:(counter*40)+40], test_size=0.2, shuffle=True, random_state=10)\n",
        "      \n",
        "      X_train += x_train.tolist()\n",
        "      X_test += x_test.tolist()\n",
        "      Y_train += y_train.tolist()\n",
        "      Y_test += y_test.tolist()  \n",
        "\n",
        "      counter += 1\n",
        "  \n",
        "  return np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)"
      ],
      "metadata": {
        "id": "XUPGk3KZyzr9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test(X, y_one_hot)"
      ],
      "metadata": {
        "id": "4Gi_VM7iZq1d"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgZLSu2N6xwX",
        "outputId": "cfc39166-0422-438d-cc0d-7cb332688a7a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2304, 20, 300)\n",
            "(576, 20, 300)\n",
            "(2304, 12)\n",
            "(576, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shuffle dataset**"
      ],
      "metadata": {
        "id": "3_NoHzKUGugN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = utils.shuffle(X_train, y_train)\n",
        "X_test, y_test = utils.shuffle(X_test, y_test)"
      ],
      "metadata": {
        "id": "fqtslTfJGt_T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
      ],
      "metadata": {
        "id": "gBx9GeczgvFI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**add channel**"
      ],
      "metadata": {
        "id": "HrmapfsWroWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "jH5Vvzz3gxmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e2b646-427b-43ee-ea6a-0637b272097c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2304, 20, 300, 1)\n",
            "(576, 20, 300, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Model**"
      ],
      "metadata": {
        "id": "Gg2ndIEA5teD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(2, 2), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size=(2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(len(categories), activation='softmax'))"
      ],
      "metadata": {
        "id": "nwYdnMQNg300"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "lRdXTKeFhGYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa9062b-732d-4e1d-fc2c-6d9bb7e4df6d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 19, 299, 64)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 10, 150, 64)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 149, 32)        8224      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9, 149, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 75, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 74, 32)         4128      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 74, 32)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 37, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 36, 128)        16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 36, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 18, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 18, 128)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                780       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 333,260\n",
            "Trainable params: 333,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "              optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Dw0YpnplhKfD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=5)"
      ],
      "metadata": {
        "id": "sEHCa6b0kRfj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "              X_train,\n",
        "              y_train,\n",
        "              batch_size=8,\n",
        "              epochs=300,\n",
        "              verbose=1,\n",
        "              validation_data=(X_test, y_test),\n",
        "              #callbacks=[earlystop_callback]\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEENQSywhPpE",
        "outputId": "0e7ac927-f0c3-4506-9813-3dd2c5be5068"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "288/288 [==============================] - 11s 7ms/step - loss: 4.4508 - accuracy: 0.0946 - val_loss: 2.5966 - val_accuracy: 0.1042\n",
            "Epoch 2/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.6737 - accuracy: 0.0964 - val_loss: 2.6006 - val_accuracy: 0.0851\n",
            "Epoch 3/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.6271 - accuracy: 0.0864 - val_loss: 2.5980 - val_accuracy: 0.0851\n",
            "Epoch 4/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 2.6061 - accuracy: 0.0894 - val_loss: 2.5935 - val_accuracy: 0.1024\n",
            "Epoch 5/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.6084 - accuracy: 0.0920 - val_loss: 2.5962 - val_accuracy: 0.0868\n",
            "Epoch 6/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.6020 - accuracy: 0.0855 - val_loss: 2.5921 - val_accuracy: 0.0955\n",
            "Epoch 7/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 2.5795 - accuracy: 0.0907 - val_loss: 2.5816 - val_accuracy: 0.1042\n",
            "Epoch 8/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.5892 - accuracy: 0.0890 - val_loss: 2.5795 - val_accuracy: 0.0816\n",
            "Epoch 9/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.5791 - accuracy: 0.0990 - val_loss: 2.5674 - val_accuracy: 0.1302\n",
            "Epoch 10/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.5635 - accuracy: 0.1068 - val_loss: 2.5483 - val_accuracy: 0.1372\n",
            "Epoch 11/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.5482 - accuracy: 0.1133 - val_loss: 2.5347 - val_accuracy: 0.1684\n",
            "Epoch 12/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 2.5084 - accuracy: 0.1237 - val_loss: 2.4780 - val_accuracy: 0.1545\n",
            "Epoch 13/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.4924 - accuracy: 0.1380 - val_loss: 2.4632 - val_accuracy: 0.1493\n",
            "Epoch 14/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.4418 - accuracy: 0.1580 - val_loss: 2.4124 - val_accuracy: 0.1788\n",
            "Epoch 15/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.4353 - accuracy: 0.1528 - val_loss: 2.3779 - val_accuracy: 0.1840\n",
            "Epoch 16/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.3822 - accuracy: 0.1567 - val_loss: 2.3858 - val_accuracy: 0.1979\n",
            "Epoch 17/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.3714 - accuracy: 0.1576 - val_loss: 2.3378 - val_accuracy: 0.2431\n",
            "Epoch 18/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.3366 - accuracy: 0.1784 - val_loss: 2.3135 - val_accuracy: 0.2448\n",
            "Epoch 19/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.2913 - accuracy: 0.1949 - val_loss: 2.2573 - val_accuracy: 0.3142\n",
            "Epoch 20/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.2544 - accuracy: 0.2070 - val_loss: 2.2233 - val_accuracy: 0.3351\n",
            "Epoch 21/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.2023 - accuracy: 0.2422 - val_loss: 2.1513 - val_accuracy: 0.3507\n",
            "Epoch 22/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.1655 - accuracy: 0.2270 - val_loss: 2.0752 - val_accuracy: 0.4115\n",
            "Epoch 23/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.1572 - accuracy: 0.2344 - val_loss: 2.0826 - val_accuracy: 0.4271\n",
            "Epoch 24/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.0743 - accuracy: 0.2869 - val_loss: 2.0002 - val_accuracy: 0.4340\n",
            "Epoch 25/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.0205 - accuracy: 0.2969 - val_loss: 1.9582 - val_accuracy: 0.4844\n",
            "Epoch 26/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.0167 - accuracy: 0.3082 - val_loss: 1.9037 - val_accuracy: 0.4896\n",
            "Epoch 27/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.9516 - accuracy: 0.3290 - val_loss: 1.8456 - val_accuracy: 0.4965\n",
            "Epoch 28/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.9196 - accuracy: 0.3320 - val_loss: 1.8172 - val_accuracy: 0.5260\n",
            "Epoch 29/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.8429 - accuracy: 0.3585 - val_loss: 1.7915 - val_accuracy: 0.5365\n",
            "Epoch 30/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.8429 - accuracy: 0.3659 - val_loss: 1.7341 - val_accuracy: 0.5312\n",
            "Epoch 31/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.7769 - accuracy: 0.3798 - val_loss: 1.6873 - val_accuracy: 0.5799\n",
            "Epoch 32/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.7359 - accuracy: 0.4084 - val_loss: 1.5875 - val_accuracy: 0.6059\n",
            "Epoch 33/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 1.7071 - accuracy: 0.4097 - val_loss: 1.5789 - val_accuracy: 0.6163\n",
            "Epoch 34/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.6197 - accuracy: 0.4436 - val_loss: 1.5018 - val_accuracy: 0.6146\n",
            "Epoch 35/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.6057 - accuracy: 0.4514 - val_loss: 1.4539 - val_accuracy: 0.6528\n",
            "Epoch 36/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.5178 - accuracy: 0.4891 - val_loss: 1.4130 - val_accuracy: 0.6615\n",
            "Epoch 37/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.5093 - accuracy: 0.4779 - val_loss: 1.4142 - val_accuracy: 0.6597\n",
            "Epoch 38/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.4704 - accuracy: 0.5143 - val_loss: 1.3486 - val_accuracy: 0.6806\n",
            "Epoch 39/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.4586 - accuracy: 0.5109 - val_loss: 1.2960 - val_accuracy: 0.6962\n",
            "Epoch 40/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.4267 - accuracy: 0.5247 - val_loss: 1.2881 - val_accuracy: 0.6875\n",
            "Epoch 41/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.3452 - accuracy: 0.5473 - val_loss: 1.2288 - val_accuracy: 0.7083\n",
            "Epoch 42/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 1.3215 - accuracy: 0.5525 - val_loss: 1.2063 - val_accuracy: 0.7066\n",
            "Epoch 43/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.2857 - accuracy: 0.5629 - val_loss: 1.1887 - val_accuracy: 0.7309\n",
            "Epoch 44/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.2690 - accuracy: 0.5825 - val_loss: 1.1369 - val_accuracy: 0.7205\n",
            "Epoch 45/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.2635 - accuracy: 0.5924 - val_loss: 1.1505 - val_accuracy: 0.7309\n",
            "Epoch 46/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.2013 - accuracy: 0.6020 - val_loss: 1.0764 - val_accuracy: 0.7344\n",
            "Epoch 47/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.1859 - accuracy: 0.6059 - val_loss: 1.0385 - val_accuracy: 0.7604\n",
            "Epoch 48/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.1118 - accuracy: 0.6359 - val_loss: 1.0033 - val_accuracy: 0.7691\n",
            "Epoch 49/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.1217 - accuracy: 0.6337 - val_loss: 0.9889 - val_accuracy: 0.7865\n",
            "Epoch 50/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.0506 - accuracy: 0.6610 - val_loss: 0.9507 - val_accuracy: 0.7726\n",
            "Epoch 51/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.0406 - accuracy: 0.6580 - val_loss: 0.9444 - val_accuracy: 0.7691\n",
            "Epoch 52/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.0064 - accuracy: 0.6905 - val_loss: 0.9012 - val_accuracy: 0.7795\n",
            "Epoch 53/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.9817 - accuracy: 0.6897 - val_loss: 0.8819 - val_accuracy: 0.7951\n",
            "Epoch 54/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.9681 - accuracy: 0.6984 - val_loss: 0.8522 - val_accuracy: 0.7830\n",
            "Epoch 55/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 0.9335 - accuracy: 0.6966 - val_loss: 0.8444 - val_accuracy: 0.8021\n",
            "Epoch 56/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8981 - accuracy: 0.7127 - val_loss: 0.8136 - val_accuracy: 0.7969\n",
            "Epoch 57/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.9151 - accuracy: 0.7031 - val_loss: 0.8279 - val_accuracy: 0.8229\n",
            "Epoch 58/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8802 - accuracy: 0.7161 - val_loss: 0.7829 - val_accuracy: 0.8177\n",
            "Epoch 59/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8879 - accuracy: 0.7253 - val_loss: 0.7849 - val_accuracy: 0.8142\n",
            "Epoch 60/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.8671 - accuracy: 0.7422 - val_loss: 0.7620 - val_accuracy: 0.8194\n",
            "Epoch 61/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8180 - accuracy: 0.7461 - val_loss: 0.7498 - val_accuracy: 0.8160\n",
            "Epoch 62/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7859 - accuracy: 0.7587 - val_loss: 0.7283 - val_accuracy: 0.8333\n",
            "Epoch 63/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8241 - accuracy: 0.7344 - val_loss: 0.7406 - val_accuracy: 0.8247\n",
            "Epoch 64/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7928 - accuracy: 0.7530 - val_loss: 0.7102 - val_accuracy: 0.8368\n",
            "Epoch 65/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8089 - accuracy: 0.7522 - val_loss: 0.7167 - val_accuracy: 0.8385\n",
            "Epoch 66/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7503 - accuracy: 0.7600 - val_loss: 0.6776 - val_accuracy: 0.8142\n",
            "Epoch 67/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7568 - accuracy: 0.7739 - val_loss: 0.6787 - val_accuracy: 0.8333\n",
            "Epoch 68/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7362 - accuracy: 0.7604 - val_loss: 0.6782 - val_accuracy: 0.8490\n",
            "Epoch 69/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7197 - accuracy: 0.7821 - val_loss: 0.6674 - val_accuracy: 0.8455\n",
            "Epoch 70/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.7208 - accuracy: 0.7817 - val_loss: 0.6598 - val_accuracy: 0.8368\n",
            "Epoch 71/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 0.7012 - accuracy: 0.7873 - val_loss: 0.6470 - val_accuracy: 0.8420\n",
            "Epoch 72/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6892 - accuracy: 0.7912 - val_loss: 0.6536 - val_accuracy: 0.8368\n",
            "Epoch 73/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6556 - accuracy: 0.7990 - val_loss: 0.6004 - val_accuracy: 0.8455\n",
            "Epoch 74/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6657 - accuracy: 0.7908 - val_loss: 0.6130 - val_accuracy: 0.8455\n",
            "Epoch 75/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6710 - accuracy: 0.7969 - val_loss: 0.6044 - val_accuracy: 0.8576\n",
            "Epoch 76/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6488 - accuracy: 0.8025 - val_loss: 0.5870 - val_accuracy: 0.8559\n",
            "Epoch 77/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6516 - accuracy: 0.8151 - val_loss: 0.6105 - val_accuracy: 0.8542\n",
            "Epoch 78/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6063 - accuracy: 0.8299 - val_loss: 0.5710 - val_accuracy: 0.8663\n",
            "Epoch 79/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6111 - accuracy: 0.8238 - val_loss: 0.5739 - val_accuracy: 0.8472\n",
            "Epoch 80/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5985 - accuracy: 0.8242 - val_loss: 0.5504 - val_accuracy: 0.8646\n",
            "Epoch 81/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6054 - accuracy: 0.8186 - val_loss: 0.5534 - val_accuracy: 0.8611\n",
            "Epoch 82/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.6028 - accuracy: 0.8177 - val_loss: 0.5648 - val_accuracy: 0.8472\n",
            "Epoch 83/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5433 - accuracy: 0.8451 - val_loss: 0.5196 - val_accuracy: 0.8733\n",
            "Epoch 84/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5654 - accuracy: 0.8355 - val_loss: 0.5230 - val_accuracy: 0.8628\n",
            "Epoch 85/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5559 - accuracy: 0.8377 - val_loss: 0.5336 - val_accuracy: 0.8750\n",
            "Epoch 86/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.5547 - accuracy: 0.8398 - val_loss: 0.5578 - val_accuracy: 0.8646\n",
            "Epoch 87/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5206 - accuracy: 0.8464 - val_loss: 0.5312 - val_accuracy: 0.8715\n",
            "Epoch 88/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5353 - accuracy: 0.8485 - val_loss: 0.5443 - val_accuracy: 0.8576\n",
            "Epoch 89/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5536 - accuracy: 0.8433 - val_loss: 0.5182 - val_accuracy: 0.8767\n",
            "Epoch 90/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5335 - accuracy: 0.8424 - val_loss: 0.4994 - val_accuracy: 0.8802\n",
            "Epoch 91/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4975 - accuracy: 0.8563 - val_loss: 0.5004 - val_accuracy: 0.8698\n",
            "Epoch 92/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4781 - accuracy: 0.8702 - val_loss: 0.4845 - val_accuracy: 0.8750\n",
            "Epoch 93/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5012 - accuracy: 0.8607 - val_loss: 0.5200 - val_accuracy: 0.8715\n",
            "Epoch 94/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.5035 - accuracy: 0.8641 - val_loss: 0.4872 - val_accuracy: 0.8750\n",
            "Epoch 95/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4914 - accuracy: 0.8659 - val_loss: 0.4966 - val_accuracy: 0.8802\n",
            "Epoch 96/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4897 - accuracy: 0.8646 - val_loss: 0.4923 - val_accuracy: 0.8698\n",
            "Epoch 97/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4695 - accuracy: 0.8698 - val_loss: 0.4760 - val_accuracy: 0.8819\n",
            "Epoch 98/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4748 - accuracy: 0.8602 - val_loss: 0.4735 - val_accuracy: 0.8750\n",
            "Epoch 99/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4538 - accuracy: 0.8763 - val_loss: 0.4839 - val_accuracy: 0.8698\n",
            "Epoch 100/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4247 - accuracy: 0.8854 - val_loss: 0.4807 - val_accuracy: 0.8767\n",
            "Epoch 101/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4362 - accuracy: 0.8707 - val_loss: 0.4519 - val_accuracy: 0.8750\n",
            "Epoch 102/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4482 - accuracy: 0.8785 - val_loss: 0.4486 - val_accuracy: 0.8854\n",
            "Epoch 103/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4233 - accuracy: 0.8724 - val_loss: 0.4643 - val_accuracy: 0.8681\n",
            "Epoch 104/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 0.4204 - accuracy: 0.8828 - val_loss: 0.4939 - val_accuracy: 0.8663\n",
            "Epoch 105/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4575 - accuracy: 0.8772 - val_loss: 0.4668 - val_accuracy: 0.8733\n",
            "Epoch 106/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4341 - accuracy: 0.8811 - val_loss: 0.4601 - val_accuracy: 0.8854\n",
            "Epoch 107/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4290 - accuracy: 0.8815 - val_loss: 0.4837 - val_accuracy: 0.8611\n",
            "Epoch 108/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4346 - accuracy: 0.8845 - val_loss: 0.4722 - val_accuracy: 0.8889\n",
            "Epoch 109/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4093 - accuracy: 0.8789 - val_loss: 0.4632 - val_accuracy: 0.8889\n",
            "Epoch 110/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4226 - accuracy: 0.8828 - val_loss: 0.4589 - val_accuracy: 0.8924\n",
            "Epoch 111/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4172 - accuracy: 0.8876 - val_loss: 0.4536 - val_accuracy: 0.8906\n",
            "Epoch 112/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3841 - accuracy: 0.8963 - val_loss: 0.4767 - val_accuracy: 0.8698\n",
            "Epoch 113/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.4004 - accuracy: 0.8954 - val_loss: 0.4846 - val_accuracy: 0.8681\n",
            "Epoch 114/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3852 - accuracy: 0.8971 - val_loss: 0.4537 - val_accuracy: 0.8819\n",
            "Epoch 115/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3871 - accuracy: 0.9015 - val_loss: 0.4579 - val_accuracy: 0.8715\n",
            "Epoch 116/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3950 - accuracy: 0.8915 - val_loss: 0.4599 - val_accuracy: 0.8854\n",
            "Epoch 117/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3907 - accuracy: 0.8928 - val_loss: 0.4533 - val_accuracy: 0.8819\n",
            "Epoch 118/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.4079 - accuracy: 0.8915 - val_loss: 0.4484 - val_accuracy: 0.8854\n",
            "Epoch 119/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3801 - accuracy: 0.9023 - val_loss: 0.4563 - val_accuracy: 0.8924\n",
            "Epoch 120/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3750 - accuracy: 0.8950 - val_loss: 0.4347 - val_accuracy: 0.8958\n",
            "Epoch 121/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3718 - accuracy: 0.8954 - val_loss: 0.4452 - val_accuracy: 0.8906\n",
            "Epoch 122/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3657 - accuracy: 0.9032 - val_loss: 0.4326 - val_accuracy: 0.8906\n",
            "Epoch 123/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3862 - accuracy: 0.8980 - val_loss: 0.4401 - val_accuracy: 0.8889\n",
            "Epoch 124/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3759 - accuracy: 0.9002 - val_loss: 0.4641 - val_accuracy: 0.8819\n",
            "Epoch 125/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3698 - accuracy: 0.9032 - val_loss: 0.4351 - val_accuracy: 0.8889\n",
            "Epoch 126/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.9158 - val_loss: 0.4378 - val_accuracy: 0.8889\n",
            "Epoch 127/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3590 - accuracy: 0.8954 - val_loss: 0.4472 - val_accuracy: 0.8819\n",
            "Epoch 128/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3659 - accuracy: 0.9119 - val_loss: 0.4288 - val_accuracy: 0.8854\n",
            "Epoch 129/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3717 - accuracy: 0.9067 - val_loss: 0.4258 - val_accuracy: 0.8941\n",
            "Epoch 130/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3512 - accuracy: 0.9149 - val_loss: 0.4225 - val_accuracy: 0.8924\n",
            "Epoch 131/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.9102 - val_loss: 0.4361 - val_accuracy: 0.8889\n",
            "Epoch 132/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3241 - accuracy: 0.9171 - val_loss: 0.4143 - val_accuracy: 0.8993\n",
            "Epoch 133/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3341 - accuracy: 0.9171 - val_loss: 0.4269 - val_accuracy: 0.8958\n",
            "Epoch 134/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3399 - accuracy: 0.9106 - val_loss: 0.4175 - val_accuracy: 0.9010\n",
            "Epoch 135/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3023 - accuracy: 0.9240 - val_loss: 0.4195 - val_accuracy: 0.8906\n",
            "Epoch 136/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3331 - accuracy: 0.9184 - val_loss: 0.4169 - val_accuracy: 0.8941\n",
            "Epoch 137/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3345 - accuracy: 0.9201 - val_loss: 0.4343 - val_accuracy: 0.8924\n",
            "Epoch 138/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3418 - accuracy: 0.9089 - val_loss: 0.4658 - val_accuracy: 0.8663\n",
            "Epoch 139/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3352 - accuracy: 0.9110 - val_loss: 0.4237 - val_accuracy: 0.8958\n",
            "Epoch 140/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.3465 - accuracy: 0.9145 - val_loss: 0.4233 - val_accuracy: 0.8976\n",
            "Epoch 141/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3365 - accuracy: 0.9145 - val_loss: 0.4268 - val_accuracy: 0.8958\n",
            "Epoch 142/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3443 - accuracy: 0.9093 - val_loss: 0.4153 - val_accuracy: 0.9045\n",
            "Epoch 143/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2859 - accuracy: 0.9353 - val_loss: 0.4132 - val_accuracy: 0.8993\n",
            "Epoch 144/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2902 - accuracy: 0.9266 - val_loss: 0.4214 - val_accuracy: 0.8941\n",
            "Epoch 145/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3217 - accuracy: 0.9162 - val_loss: 0.4237 - val_accuracy: 0.9028\n",
            "Epoch 146/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3208 - accuracy: 0.9197 - val_loss: 0.4260 - val_accuracy: 0.8889\n",
            "Epoch 147/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3048 - accuracy: 0.9306 - val_loss: 0.4403 - val_accuracy: 0.8785\n",
            "Epoch 148/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2934 - accuracy: 0.9301 - val_loss: 0.4881 - val_accuracy: 0.8785\n",
            "Epoch 149/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3032 - accuracy: 0.9275 - val_loss: 0.4272 - val_accuracy: 0.8906\n",
            "Epoch 150/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2843 - accuracy: 0.9297 - val_loss: 0.4302 - val_accuracy: 0.8906\n",
            "Epoch 151/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2994 - accuracy: 0.9197 - val_loss: 0.4364 - val_accuracy: 0.8941\n",
            "Epoch 152/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2859 - accuracy: 0.9301 - val_loss: 0.4533 - val_accuracy: 0.8958\n",
            "Epoch 153/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 0.2964 - accuracy: 0.9258 - val_loss: 0.4570 - val_accuracy: 0.8837\n",
            "Epoch 154/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3204 - accuracy: 0.9180 - val_loss: 0.4185 - val_accuracy: 0.9010\n",
            "Epoch 155/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3033 - accuracy: 0.9310 - val_loss: 0.4228 - val_accuracy: 0.9010\n",
            "Epoch 156/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3039 - accuracy: 0.9253 - val_loss: 0.4469 - val_accuracy: 0.8924\n",
            "Epoch 157/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2955 - accuracy: 0.9293 - val_loss: 0.4741 - val_accuracy: 0.8819\n",
            "Epoch 158/300\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 0.2969 - accuracy: 0.9306 - val_loss: 0.4383 - val_accuracy: 0.8889\n",
            "Epoch 159/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2839 - accuracy: 0.9340 - val_loss: 0.4432 - val_accuracy: 0.8976\n",
            "Epoch 160/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2991 - accuracy: 0.9275 - val_loss: 0.4274 - val_accuracy: 0.9115\n",
            "Epoch 161/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2919 - accuracy: 0.9297 - val_loss: 0.4099 - val_accuracy: 0.9028\n",
            "Epoch 162/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2930 - accuracy: 0.9306 - val_loss: 0.4374 - val_accuracy: 0.8976\n",
            "Epoch 163/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2903 - accuracy: 0.9266 - val_loss: 0.4279 - val_accuracy: 0.8993\n",
            "Epoch 164/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2970 - accuracy: 0.9349 - val_loss: 0.4428 - val_accuracy: 0.8889\n",
            "Epoch 165/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2774 - accuracy: 0.9345 - val_loss: 0.4839 - val_accuracy: 0.8889\n",
            "Epoch 166/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.2475 - accuracy: 0.9466 - val_loss: 0.4265 - val_accuracy: 0.9045\n",
            "Epoch 167/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2657 - accuracy: 0.9366 - val_loss: 0.4235 - val_accuracy: 0.8993\n",
            "Epoch 168/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2698 - accuracy: 0.9358 - val_loss: 0.4226 - val_accuracy: 0.9028\n",
            "Epoch 169/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2749 - accuracy: 0.9392 - val_loss: 0.4164 - val_accuracy: 0.9010\n",
            "Epoch 170/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2655 - accuracy: 0.9362 - val_loss: 0.4183 - val_accuracy: 0.8889\n",
            "Epoch 171/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2723 - accuracy: 0.9384 - val_loss: 0.4192 - val_accuracy: 0.8924\n",
            "Epoch 172/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2850 - accuracy: 0.9340 - val_loss: 0.4096 - val_accuracy: 0.8924\n",
            "Epoch 173/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2640 - accuracy: 0.9323 - val_loss: 0.4365 - val_accuracy: 0.8924\n",
            "Epoch 174/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2403 - accuracy: 0.9466 - val_loss: 0.4626 - val_accuracy: 0.8854\n",
            "Epoch 175/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2592 - accuracy: 0.9405 - val_loss: 0.4446 - val_accuracy: 0.9028\n",
            "Epoch 176/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2661 - accuracy: 0.9388 - val_loss: 0.4154 - val_accuracy: 0.9062\n",
            "Epoch 177/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2693 - accuracy: 0.9336 - val_loss: 0.4349 - val_accuracy: 0.8993\n",
            "Epoch 178/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2497 - accuracy: 0.9414 - val_loss: 0.4276 - val_accuracy: 0.8924\n",
            "Epoch 179/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2537 - accuracy: 0.9470 - val_loss: 0.4369 - val_accuracy: 0.8941\n",
            "Epoch 180/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.3166 - accuracy: 0.9323 - val_loss: 0.4344 - val_accuracy: 0.9045\n",
            "Epoch 181/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2546 - accuracy: 0.9431 - val_loss: 0.4665 - val_accuracy: 0.8872\n",
            "Epoch 182/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2494 - accuracy: 0.9440 - val_loss: 0.4391 - val_accuracy: 0.8889\n",
            "Epoch 183/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2550 - accuracy: 0.9501 - val_loss: 0.4212 - val_accuracy: 0.9028\n",
            "Epoch 184/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2717 - accuracy: 0.9323 - val_loss: 0.4154 - val_accuracy: 0.8958\n",
            "Epoch 185/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2387 - accuracy: 0.9436 - val_loss: 0.4274 - val_accuracy: 0.9010\n",
            "Epoch 186/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2638 - accuracy: 0.9397 - val_loss: 0.4241 - val_accuracy: 0.9097\n",
            "Epoch 187/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2161 - accuracy: 0.9536 - val_loss: 0.4469 - val_accuracy: 0.9010\n",
            "Epoch 188/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2569 - accuracy: 0.9423 - val_loss: 0.4712 - val_accuracy: 0.8976\n",
            "Epoch 189/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2483 - accuracy: 0.9431 - val_loss: 0.4149 - val_accuracy: 0.8958\n",
            "Epoch 190/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2277 - accuracy: 0.9497 - val_loss: 0.4353 - val_accuracy: 0.8958\n",
            "Epoch 191/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2262 - accuracy: 0.9492 - val_loss: 0.4246 - val_accuracy: 0.9010\n",
            "Epoch 192/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.2520 - accuracy: 0.9414 - val_loss: 0.4203 - val_accuracy: 0.9062\n",
            "Epoch 193/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2569 - accuracy: 0.9440 - val_loss: 0.4367 - val_accuracy: 0.8906\n",
            "Epoch 194/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2573 - accuracy: 0.9436 - val_loss: 0.4216 - val_accuracy: 0.9097\n",
            "Epoch 195/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2292 - accuracy: 0.9475 - val_loss: 0.4070 - val_accuracy: 0.9080\n",
            "Epoch 196/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2337 - accuracy: 0.9462 - val_loss: 0.3923 - val_accuracy: 0.9115\n",
            "Epoch 197/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2523 - accuracy: 0.9475 - val_loss: 0.4140 - val_accuracy: 0.9045\n",
            "Epoch 198/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2382 - accuracy: 0.9475 - val_loss: 0.3982 - val_accuracy: 0.9080\n",
            "Epoch 199/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2209 - accuracy: 0.9501 - val_loss: 0.4398 - val_accuracy: 0.8889\n",
            "Epoch 200/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2289 - accuracy: 0.9475 - val_loss: 0.3989 - val_accuracy: 0.9080\n",
            "Epoch 201/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2521 - accuracy: 0.9457 - val_loss: 0.4153 - val_accuracy: 0.9149\n",
            "Epoch 202/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2583 - accuracy: 0.9423 - val_loss: 0.3954 - val_accuracy: 0.9028\n",
            "Epoch 203/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2269 - accuracy: 0.9462 - val_loss: 0.3887 - val_accuracy: 0.9062\n",
            "Epoch 204/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2350 - accuracy: 0.9497 - val_loss: 0.4101 - val_accuracy: 0.9010\n",
            "Epoch 205/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2453 - accuracy: 0.9449 - val_loss: 0.4202 - val_accuracy: 0.9062\n",
            "Epoch 206/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2287 - accuracy: 0.9488 - val_loss: 0.4056 - val_accuracy: 0.9062\n",
            "Epoch 207/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2210 - accuracy: 0.9518 - val_loss: 0.4569 - val_accuracy: 0.8958\n",
            "Epoch 208/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2260 - accuracy: 0.9540 - val_loss: 0.4179 - val_accuracy: 0.8976\n",
            "Epoch 209/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2349 - accuracy: 0.9514 - val_loss: 0.4214 - val_accuracy: 0.9010\n",
            "Epoch 210/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2183 - accuracy: 0.9479 - val_loss: 0.4736 - val_accuracy: 0.8958\n",
            "Epoch 211/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2345 - accuracy: 0.9501 - val_loss: 0.4219 - val_accuracy: 0.9010\n",
            "Epoch 212/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2427 - accuracy: 0.9501 - val_loss: 0.4216 - val_accuracy: 0.8976\n",
            "Epoch 213/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2047 - accuracy: 0.9579 - val_loss: 0.4139 - val_accuracy: 0.9028\n",
            "Epoch 214/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2053 - accuracy: 0.9497 - val_loss: 0.4827 - val_accuracy: 0.8854\n",
            "Epoch 215/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2342 - accuracy: 0.9466 - val_loss: 0.4930 - val_accuracy: 0.8941\n",
            "Epoch 216/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2264 - accuracy: 0.9566 - val_loss: 0.4519 - val_accuracy: 0.8889\n",
            "Epoch 217/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2111 - accuracy: 0.9562 - val_loss: 0.4066 - val_accuracy: 0.8976\n",
            "Epoch 218/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.2110 - accuracy: 0.9566 - val_loss: 0.4470 - val_accuracy: 0.8924\n",
            "Epoch 219/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.2203 - accuracy: 0.9475 - val_loss: 0.4331 - val_accuracy: 0.8941\n",
            "Epoch 220/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2040 - accuracy: 0.9592 - val_loss: 0.4204 - val_accuracy: 0.9080\n",
            "Epoch 221/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2391 - accuracy: 0.9484 - val_loss: 0.4144 - val_accuracy: 0.9010\n",
            "Epoch 222/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2294 - accuracy: 0.9588 - val_loss: 0.4224 - val_accuracy: 0.8993\n",
            "Epoch 223/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2202 - accuracy: 0.9527 - val_loss: 0.4247 - val_accuracy: 0.8958\n",
            "Epoch 224/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2092 - accuracy: 0.9549 - val_loss: 0.4205 - val_accuracy: 0.9028\n",
            "Epoch 225/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1894 - accuracy: 0.9575 - val_loss: 0.4428 - val_accuracy: 0.9045\n",
            "Epoch 226/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2206 - accuracy: 0.9527 - val_loss: 0.3965 - val_accuracy: 0.9062\n",
            "Epoch 227/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2197 - accuracy: 0.9544 - val_loss: 0.4060 - val_accuracy: 0.9080\n",
            "Epoch 228/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2039 - accuracy: 0.9562 - val_loss: 0.3840 - val_accuracy: 0.9132\n",
            "Epoch 229/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2206 - accuracy: 0.9536 - val_loss: 0.4686 - val_accuracy: 0.8889\n",
            "Epoch 230/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2035 - accuracy: 0.9553 - val_loss: 0.4367 - val_accuracy: 0.9028\n",
            "Epoch 231/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2186 - accuracy: 0.9544 - val_loss: 0.4137 - val_accuracy: 0.9045\n",
            "Epoch 232/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2062 - accuracy: 0.9518 - val_loss: 0.4030 - val_accuracy: 0.9062\n",
            "Epoch 233/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2055 - accuracy: 0.9596 - val_loss: 0.3936 - val_accuracy: 0.9149\n",
            "Epoch 234/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1910 - accuracy: 0.9618 - val_loss: 0.3927 - val_accuracy: 0.9045\n",
            "Epoch 235/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2118 - accuracy: 0.9531 - val_loss: 0.4052 - val_accuracy: 0.9097\n",
            "Epoch 236/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2122 - accuracy: 0.9553 - val_loss: 0.4229 - val_accuracy: 0.9045\n",
            "Epoch 237/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2114 - accuracy: 0.9536 - val_loss: 0.4117 - val_accuracy: 0.9062\n",
            "Epoch 238/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2217 - accuracy: 0.9518 - val_loss: 0.3993 - val_accuracy: 0.9062\n",
            "Epoch 239/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1834 - accuracy: 0.9622 - val_loss: 0.4190 - val_accuracy: 0.9028\n",
            "Epoch 240/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2181 - accuracy: 0.9518 - val_loss: 0.4154 - val_accuracy: 0.9045\n",
            "Epoch 241/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1885 - accuracy: 0.9570 - val_loss: 0.4040 - val_accuracy: 0.9045\n",
            "Epoch 242/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1810 - accuracy: 0.9648 - val_loss: 0.4273 - val_accuracy: 0.9097\n",
            "Epoch 243/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2180 - accuracy: 0.9570 - val_loss: 0.4041 - val_accuracy: 0.8958\n",
            "Epoch 244/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.1933 - accuracy: 0.9592 - val_loss: 0.4142 - val_accuracy: 0.8976\n",
            "Epoch 245/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.2153 - accuracy: 0.9479 - val_loss: 0.4373 - val_accuracy: 0.8941\n",
            "Epoch 246/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2246 - accuracy: 0.9505 - val_loss: 0.4450 - val_accuracy: 0.8941\n",
            "Epoch 247/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2192 - accuracy: 0.9553 - val_loss: 0.4441 - val_accuracy: 0.8941\n",
            "Epoch 248/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1987 - accuracy: 0.9601 - val_loss: 0.4203 - val_accuracy: 0.9028\n",
            "Epoch 249/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1807 - accuracy: 0.9609 - val_loss: 0.4278 - val_accuracy: 0.9028\n",
            "Epoch 250/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2195 - accuracy: 0.9505 - val_loss: 0.4310 - val_accuracy: 0.8941\n",
            "Epoch 251/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2097 - accuracy: 0.9553 - val_loss: 0.4424 - val_accuracy: 0.8906\n",
            "Epoch 252/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1925 - accuracy: 0.9588 - val_loss: 0.4350 - val_accuracy: 0.8941\n",
            "Epoch 253/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1922 - accuracy: 0.9609 - val_loss: 0.4225 - val_accuracy: 0.8889\n",
            "Epoch 254/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1762 - accuracy: 0.9631 - val_loss: 0.4533 - val_accuracy: 0.8958\n",
            "Epoch 255/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2111 - accuracy: 0.9566 - val_loss: 0.4592 - val_accuracy: 0.8958\n",
            "Epoch 256/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1826 - accuracy: 0.9640 - val_loss: 0.3980 - val_accuracy: 0.9097\n",
            "Epoch 257/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1918 - accuracy: 0.9605 - val_loss: 0.4027 - val_accuracy: 0.9167\n",
            "Epoch 258/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2177 - accuracy: 0.9527 - val_loss: 0.4452 - val_accuracy: 0.8906\n",
            "Epoch 259/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1943 - accuracy: 0.9609 - val_loss: 0.4955 - val_accuracy: 0.9010\n",
            "Epoch 260/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2084 - accuracy: 0.9570 - val_loss: 0.4053 - val_accuracy: 0.9045\n",
            "Epoch 261/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2140 - accuracy: 0.9553 - val_loss: 0.4220 - val_accuracy: 0.9010\n",
            "Epoch 262/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1814 - accuracy: 0.9653 - val_loss: 0.3920 - val_accuracy: 0.9097\n",
            "Epoch 263/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2066 - accuracy: 0.9601 - val_loss: 0.4161 - val_accuracy: 0.9045\n",
            "Epoch 264/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1853 - accuracy: 0.9635 - val_loss: 0.4412 - val_accuracy: 0.8941\n",
            "Epoch 265/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1930 - accuracy: 0.9622 - val_loss: 0.3955 - val_accuracy: 0.9062\n",
            "Epoch 266/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1910 - accuracy: 0.9588 - val_loss: 0.4162 - val_accuracy: 0.8941\n",
            "Epoch 267/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1845 - accuracy: 0.9635 - val_loss: 0.4329 - val_accuracy: 0.9062\n",
            "Epoch 268/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1742 - accuracy: 0.9679 - val_loss: 0.4203 - val_accuracy: 0.8993\n",
            "Epoch 269/300\n",
            "288/288 [==============================] - 2s 9ms/step - loss: 0.2127 - accuracy: 0.9553 - val_loss: 0.4472 - val_accuracy: 0.8976\n",
            "Epoch 270/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1932 - accuracy: 0.9592 - val_loss: 0.4640 - val_accuracy: 0.8889\n",
            "Epoch 271/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1780 - accuracy: 0.9653 - val_loss: 0.4617 - val_accuracy: 0.8854\n",
            "Epoch 272/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.1992 - accuracy: 0.9575 - val_loss: 0.4584 - val_accuracy: 0.8906\n",
            "Epoch 273/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2041 - accuracy: 0.9609 - val_loss: 0.4539 - val_accuracy: 0.8906\n",
            "Epoch 274/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1747 - accuracy: 0.9657 - val_loss: 0.4597 - val_accuracy: 0.8993\n",
            "Epoch 275/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1993 - accuracy: 0.9583 - val_loss: 0.4946 - val_accuracy: 0.8993\n",
            "Epoch 276/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1785 - accuracy: 0.9618 - val_loss: 0.4538 - val_accuracy: 0.9028\n",
            "Epoch 277/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1796 - accuracy: 0.9683 - val_loss: 0.4443 - val_accuracy: 0.8993\n",
            "Epoch 278/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1900 - accuracy: 0.9605 - val_loss: 0.4333 - val_accuracy: 0.8924\n",
            "Epoch 279/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1699 - accuracy: 0.9701 - val_loss: 0.4730 - val_accuracy: 0.8993\n",
            "Epoch 280/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1750 - accuracy: 0.9661 - val_loss: 0.4800 - val_accuracy: 0.8958\n",
            "Epoch 281/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1879 - accuracy: 0.9627 - val_loss: 0.4622 - val_accuracy: 0.8924\n",
            "Epoch 282/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1939 - accuracy: 0.9618 - val_loss: 0.4851 - val_accuracy: 0.8976\n",
            "Epoch 283/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1835 - accuracy: 0.9622 - val_loss: 0.4378 - val_accuracy: 0.8889\n",
            "Epoch 284/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1865 - accuracy: 0.9627 - val_loss: 0.4838 - val_accuracy: 0.8906\n",
            "Epoch 285/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1767 - accuracy: 0.9674 - val_loss: 0.4624 - val_accuracy: 0.8976\n",
            "Epoch 286/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1873 - accuracy: 0.9640 - val_loss: 0.4683 - val_accuracy: 0.8993\n",
            "Epoch 287/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.2013 - accuracy: 0.9549 - val_loss: 0.4949 - val_accuracy: 0.8924\n",
            "Epoch 288/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1690 - accuracy: 0.9674 - val_loss: 0.4589 - val_accuracy: 0.8872\n",
            "Epoch 289/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1732 - accuracy: 0.9631 - val_loss: 0.4533 - val_accuracy: 0.8941\n",
            "Epoch 290/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1841 - accuracy: 0.9596 - val_loss: 0.4543 - val_accuracy: 0.8924\n",
            "Epoch 291/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1904 - accuracy: 0.9653 - val_loss: 0.4551 - val_accuracy: 0.8872\n",
            "Epoch 292/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1958 - accuracy: 0.9644 - val_loss: 0.4368 - val_accuracy: 0.9028\n",
            "Epoch 293/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1980 - accuracy: 0.9575 - val_loss: 0.4291 - val_accuracy: 0.8924\n",
            "Epoch 294/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.1775 - accuracy: 0.9622 - val_loss: 0.4170 - val_accuracy: 0.9010\n",
            "Epoch 295/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.1799 - accuracy: 0.9605 - val_loss: 0.4273 - val_accuracy: 0.9080\n",
            "Epoch 296/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1615 - accuracy: 0.9670 - val_loss: 0.4471 - val_accuracy: 0.9045\n",
            "Epoch 297/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1642 - accuracy: 0.9688 - val_loss: 0.4901 - val_accuracy: 0.8889\n",
            "Epoch 298/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1862 - accuracy: 0.9653 - val_loss: 0.4349 - val_accuracy: 0.8958\n",
            "Epoch 299/300\n",
            "288/288 [==============================] - 2s 7ms/step - loss: 0.1654 - accuracy: 0.9696 - val_loss: 0.4323 - val_accuracy: 0.8924\n",
            "Epoch 300/300\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.1653 - accuracy: 0.9635 - val_loss: 0.4145 - val_accuracy: 0.9028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate network on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"\\ntest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYNSshVKUQXJ",
        "outputId": "a5089bbd-edfb-4ed2-f68f-121d26455568"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 1s 6ms/step - loss: 0.4145 - accuracy: 0.9028\n",
            "\n",
            "test loss: 0.41450533270835876, test accuracy: 90.27777910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "4hbM58IDUZpS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prediction**"
      ],
      "metadata": {
        "id": "w2_PDibBP8n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 300\n",
        "def signal2mfcc(file_path, max_len=MAX_LEN):\n",
        "    signal, sample_rate = lr.load(file_path, mono=True, sr=None)\n",
        "    mfcc = lr.feature.mfcc(signal, sample_rate)\n",
        "\n",
        "    if (max_len > mfcc.shape[1]):\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    \n",
        "    return mfcc"
      ],
      "metadata": {
        "id": "JJnFpXZHeTZJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(audio_path):\n",
        "    audio_file = glob(audio_path)\n",
        "    MFCCs = signal2mfcc(audio_file[0])\n",
        "    MFCCs = MFCCs.reshape(1,20,300,1)\n",
        "    prediction = model.predict(MFCCs)[0]\n",
        "    print(prediction)\n",
        "    category_index = np.where(prediction == max(prediction))[0][0]\n",
        "    print(category_index)\n",
        "    result = categories[category_index]\n",
        "    return result"
      ],
      "metadata": {
        "id": "RktI5Dc2P_UL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('/content/dataset/19/40-(19).mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "C-3bq2jUQs-D",
        "outputId": "0f1356d4-6873-4fb0-84f3-c5e8170ab754"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "[5.9255871e-07 8.1343472e-08 3.0726619e-09 8.0672107e-05 1.3127899e-13\n",
            " 6.3199858e-12 9.3408738e-07 9.0253404e-16 5.7830693e-14 2.6646486e-18\n",
            " 9.9991775e-01 2.1652857e-11]\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'مشتقات'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-6wRuJQuqQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}